{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8049633,"sourceType":"datasetVersion","datasetId":4746902}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\n!pip install torchsummary\nimport torch.nn as nn\nfrom torchvision import models\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T01:00:21.246864Z","iopub.execute_input":"2024-04-08T01:00:21.247603Z","iopub.status.idle":"2024-04-08T01:00:42.182473Z","shell.execute_reply.started":"2024-04-08T01:00:21.247490Z","shell.execute_reply":"2024-04-08T01:00:42.181204Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:00:56.585541Z","iopub.execute_input":"2024-04-08T01:00:56.586474Z","iopub.status.idle":"2024-04-08T01:00:56.648184Z","shell.execute_reply.started":"2024-04-08T01:00:56.586439Z","shell.execute_reply":"2024-04-08T01:00:56.647261Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"# minibatch size\nbatch_size = 4","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:00:57.622296Z","iopub.execute_input":"2024-04-08T01:00:57.622671Z","iopub.status.idle":"2024-04-08T01:00:57.627049Z","shell.execute_reply.started":"2024-04-08T01:00:57.622641Z","shell.execute_reply":"2024-04-08T01:00:57.625972Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\n\n\n# Define resize operation if needed\nresize = transforms.Resize((48, 48))  # Replace with (96, 96) if upsizing is desired\n\n# Define transformations for training, validation, and testing\ntrainTransforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n    resize,\n    transforms.RandomHorizontalFlip(),  # Data augmentation\n    transforms.RandomRotation(10),  # Data augmentation\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),  # Normalizing for grayscale image\n])\n\nvalidationTransforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n    resize,\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),\n])\n\ntestTransforms = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n    resize,\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:01:17.922651Z","iopub.execute_input":"2024-04-08T01:01:17.923013Z","iopub.status.idle":"2024-04-08T01:01:17.931311Z","shell.execute_reply.started":"2024-04-08T01:01:17.922985Z","shell.execute_reply":"2024-04-08T01:01:17.930427Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split\n\n\n\n\n# Load the dataset from the image folder\ndataset = datasets.ImageFolder(root='/kaggle/input/fer-2013/train', transform=trainTransforms)\n\n# Calculate the sizes for train and validation sets\ntrain_size = int(0.7 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Split the dataset\ntrain_data, validation_data = random_split(dataset, [train_size, val_size])\n# Setup the batch size hyperparameter\nBATCH_SIZE = batch_size\ntest_data = ImageFolder('/kaggle/input/fer-2013/test', transform=testTransforms)\n\n# Turn datasets into iterables (batches)\ntrain_dataloader = DataLoader(train_data,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\nvalidation_dataloader = DataLoader(validation_data,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\ntest_dataloader = DataLoader(test_data,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False)\n\n\n# Let's check out what we've created\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of Validation dataloader: {len(validation_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:01:27.824872Z","iopub.execute_input":"2024-04-08T01:01:27.825237Z","iopub.status.idle":"2024-04-08T01:02:12.348605Z","shell.execute_reply.started":"2024-04-08T01:01:27.825209Z","shell.execute_reply":"2024-04-08T01:02:12.347692Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7dd941c33910>, <torch.utils.data.dataloader.DataLoader object at 0x7dd941c33c70>)\nLength of train dataloader: 5024 batches of 4\nLength of Validation dataloader: 2154 batches of 4\nLength of test dataloader: 1795 batches of 4\n","output_type":"stream"}]},{"cell_type":"code","source":"nb_train_samples = 5024 * 4\nnb_validation_samples = 2154 * 4\nnb_test_samples = 1795 * 4","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:02:17.471749Z","iopub.execute_input":"2024-04-08T01:02:17.472071Z","iopub.status.idle":"2024-04-08T01:02:17.476529Z","shell.execute_reply.started":"2024-04-08T01:02:17.472046Z","shell.execute_reply":"2024-04-08T01:02:17.475482Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Defining the neural network\nclass FIVE_CNN(nn.Module):\n    def __init__(self):\n        super(FIVE_CNN, self).__init__()\n        \n        # Convolutional blocks: Conv layer => BatchNorm => ReLU\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Adaptive average pooling\n        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Fully connected layer\n        self.fc = nn.Linear(1024, 7) \n        \n  \n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n        x = self.adaptive_avg_pool(x)\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n        x = self.fc(x)\n        return x\n\n# Instantiating the model\nmodel = FIVE_CNN()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T02:39:40.519581Z","iopub.execute_input":"2024-04-08T02:39:40.520337Z","iopub.status.idle":"2024-04-08T02:39:40.598290Z","shell.execute_reply.started":"2024-04-08T02:39:40.520305Z","shell.execute_reply":"2024-04-08T02:39:40.597531Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# FOCAL LOSS","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def forward(self, input, target):\n        ce_loss = F.cross_entropy(input, target, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = (1 - pt) ** self.gamma * ce_loss\n        if self.alpha is not None:\n            focal_loss = self.alpha * focal_loss\n        return focal_loss.mean()\n\n# Usage example:\n# Instantiate Focal Loss\ncriterion = FocalLoss(gamma=2, alpha=None)\n\n# Then, in your training loop, use this `criterion` as your loss function:\n# loss = criterion(outputs, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:03:51.322751Z","iopub.execute_input":"2024-04-08T01:03:51.323365Z","iopub.status.idle":"2024-04-08T01:03:51.330777Z","shell.execute_reply.started":"2024-04-08T01:03:51.323334Z","shell.execute_reply":"2024-04-08T01:03:51.329826Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Criterion and Optimizer\n#criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\nmodel=model.to(device)\n# Scheduler\nscheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.75, patience=5, verbose=True)\n\nnum_epochs = 25\nprint(torch.cuda.is_available())\n\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n\n    for inputs, labels in train_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        _, preds = torch.max(outputs, 1)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / len(train_dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Training loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n    # Validation phase\n    model.eval()\n    val_running_loss = 0.0\n    val_running_corrects = 0\n    with torch.no_grad():\n        for inputs, labels in validation_dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            val_running_loss += loss.item() * inputs.size(0)\n            val_running_corrects += torch.sum(preds == labels.data)\n\n    val_epoch_loss = val_running_loss / len(validation_dataloader.dataset)\n    val_epoch_acc = val_running_corrects.double() / len(validation_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Validation loss: {val_epoch_loss:.4f}, Accuracy: {val_epoch_acc:.4f}')\n\n    # Adjust learning rate based on validation accuracy\n    scheduler.step(val_epoch_acc)\n\n# Save the model after training\ntorch.save(model.state_dict(), 'vggnet_fer.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:04:00.049777Z","iopub.execute_input":"2024-04-08T01:04:00.050457Z","iopub.status.idle":"2024-04-08T01:46:31.040895Z","shell.execute_reply.started":"2024-04-08T01:04:00.050428Z","shell.execute_reply":"2024-04-08T01:46:31.039986Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"True\nEpoch 0/24 - Training loss: 1.2278, Accuracy: 0.3029\nEpoch 0/24 - Validation loss: 1.0638, Accuracy: 0.3831\nEpoch 1/24 - Training loss: 1.0320, Accuracy: 0.3980\nEpoch 1/24 - Validation loss: 0.9593, Accuracy: 0.4306\nEpoch 2/24 - Training loss: 0.9550, Accuracy: 0.4368\nEpoch 2/24 - Validation loss: 0.9086, Accuracy: 0.4602\nEpoch 3/24 - Training loss: 0.8980, Accuracy: 0.4600\nEpoch 3/24 - Validation loss: 0.8588, Accuracy: 0.4806\nEpoch 4/24 - Training loss: 0.8623, Accuracy: 0.4800\nEpoch 4/24 - Validation loss: 0.8442, Accuracy: 0.4737\nEpoch 5/24 - Training loss: 0.8437, Accuracy: 0.4908\nEpoch 5/24 - Validation loss: 0.8326, Accuracy: 0.5091\nEpoch 6/24 - Training loss: 0.8149, Accuracy: 0.5004\nEpoch 6/24 - Validation loss: 0.8090, Accuracy: 0.5093\nEpoch 7/24 - Training loss: 0.7910, Accuracy: 0.5151\nEpoch 7/24 - Validation loss: 0.8501, Accuracy: 0.4720\nEpoch 8/24 - Training loss: 0.7799, Accuracy: 0.5200\nEpoch 8/24 - Validation loss: 0.8379, Accuracy: 0.4860\nEpoch 9/24 - Training loss: 0.7538, Accuracy: 0.5295\nEpoch 9/24 - Validation loss: 0.8020, Accuracy: 0.4871\nEpoch 10/24 - Training loss: 0.7422, Accuracy: 0.5341\nEpoch 10/24 - Validation loss: 0.7565, Accuracy: 0.5383\nEpoch 11/24 - Training loss: 0.7139, Accuracy: 0.5463\nEpoch 11/24 - Validation loss: 0.7532, Accuracy: 0.5283\nEpoch 12/24 - Training loss: 0.7096, Accuracy: 0.5496\nEpoch 12/24 - Validation loss: 0.7556, Accuracy: 0.5077\nEpoch 13/24 - Training loss: 0.6990, Accuracy: 0.5571\nEpoch 13/24 - Validation loss: 0.7506, Accuracy: 0.5503\nEpoch 14/24 - Training loss: 0.6763, Accuracy: 0.5624\nEpoch 14/24 - Validation loss: 0.7562, Accuracy: 0.5446\nEpoch 15/24 - Training loss: 0.6627, Accuracy: 0.5746\nEpoch 15/24 - Validation loss: 0.7607, Accuracy: 0.5304\nEpoch 16/24 - Training loss: 0.6459, Accuracy: 0.5808\nEpoch 16/24 - Validation loss: 0.7207, Accuracy: 0.5596\nEpoch 17/24 - Training loss: 0.6417, Accuracy: 0.5817\nEpoch 17/24 - Validation loss: 0.7509, Accuracy: 0.5351\nEpoch 18/24 - Training loss: 0.6423, Accuracy: 0.5820\nEpoch 18/24 - Validation loss: 0.7651, Accuracy: 0.5362\nEpoch 19/24 - Training loss: 0.6203, Accuracy: 0.5967\nEpoch 19/24 - Validation loss: 0.7500, Accuracy: 0.5568\nEpoch 20/24 - Training loss: 0.6103, Accuracy: 0.5930\nEpoch 20/24 - Validation loss: 0.7248, Accuracy: 0.5626\nEpoch 21/24 - Training loss: 0.6102, Accuracy: 0.5996\nEpoch 21/24 - Validation loss: 0.7172, Accuracy: 0.5633\nEpoch 22/24 - Training loss: 0.5965, Accuracy: 0.6050\nEpoch 22/24 - Validation loss: 0.7398, Accuracy: 0.5563\nEpoch 23/24 - Training loss: 0.5870, Accuracy: 0.6059\nEpoch 23/24 - Validation loss: 0.7289, Accuracy: 0.5412\nEpoch 24/24 - Training loss: 0.5848, Accuracy: 0.6071\nEpoch 24/24 - Validation loss: 0.7015, Accuracy: 0.5631\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\ntest_loss = 0.0\ntest_corrects = 0\n\n# You should define nb_test_samples before this block\n# It should be the total number of samples in the test set\nnb_test_samples = len(test_dataloader.dataset)\n\nwith torch.no_grad():\n    for inputs, labels in test_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item() * inputs.size(0)\n\n        _, preds = torch.max(outputs, 1)\n        test_corrects += torch.sum(preds == labels.data).item()\n\n# Calculate the average loss and accuracy\ntest_epoch_loss = test_loss / nb_test_samples\ntest_epoch_accuracy = test_corrects / nb_test_samples\ntest_accuracy_percentage = test_epoch_accuracy * 100\n\nprint(f'Test loss: {test_epoch_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy_percentage:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:51:34.286256Z","iopub.execute_input":"2024-04-08T01:51:34.286994Z","iopub.status.idle":"2024-04-08T01:52:23.086887Z","shell.execute_reply.started":"2024-04-08T01:51:34.286962Z","shell.execute_reply":"2024-04-08T01:52:23.085926Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Test loss: 0.6841\nTest Accuracy: 56.91%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Kullback Leibler Divergence Loss ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Define Kullback-Leibler Divergence (KLD) Loss Function\nimport torch.nn.functional as F\n\ndef kld_loss(outputs, labels):\n    log_probs = F.log_softmax(outputs, dim=1)\n    target_probs = F.one_hot(labels, num_classes=outputs.size(1))  # Convert labels to one-hot vectors\n    target_probs = target_probs.float()\n    return F.kl_div(log_probs, target_probs, reduction='batchmean')\n \n\n# Adam Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n# Number of epochs\nnum_epochs = 25\n\n\n\n# Move model to GPU if available\nmodel = model.to(device)\n\n# Training Loop\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n\n    for inputs, labels in train_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = kld_loss(outputs, labels)  # Use KLD loss here\n        _, preds = torch.max(outputs, 1)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / len(train_dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Training loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n    # Validation phase\n    model.eval()\n    val_running_loss = 0.0\n    val_running_corrects = 0\n    \n    with torch.no_grad():\n        for inputs, labels in validation_dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = kld_loss(outputs, labels)  # Use KLD loss here\n            _, preds = torch.max(outputs, 1)\n            val_running_loss += loss.item() * inputs.size(0)\n            val_running_corrects += torch.sum(preds == labels.data)\n\n    val_epoch_loss = val_running_loss / len(validation_dataloader.dataset)\n    val_epoch_acc = val_running_corrects.double() / len(validation_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Validation loss: {val_epoch_loss:.4f}, Accuracy: {val_epoch_acc:.4f}')\n\n    \n\n# Save the model after training\ntorch.save(model.state_dict(), 'vggnet_kld_adam.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T02:39:54.583063Z","iopub.execute_input":"2024-04-08T02:39:54.583750Z","iopub.status.idle":"2024-04-08T03:09:28.165714Z","shell.execute_reply.started":"2024-04-08T02:39:54.583719Z","shell.execute_reply":"2024-04-08T03:09:28.164720Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 0/24 - Training loss: 1.6253, Accuracy: 0.3607\nEpoch 0/24 - Validation loss: 1.4222, Accuracy: 0.4502\nEpoch 1/24 - Training loss: 1.3233, Accuracy: 0.4885\nEpoch 1/24 - Validation loss: 1.2796, Accuracy: 0.5170\nEpoch 2/24 - Training loss: 1.2153, Accuracy: 0.5355\nEpoch 2/24 - Validation loss: 1.1940, Accuracy: 0.5435\nEpoch 3/24 - Training loss: 1.1408, Accuracy: 0.5670\nEpoch 3/24 - Validation loss: 1.1699, Accuracy: 0.5590\nEpoch 4/24 - Training loss: 1.0834, Accuracy: 0.5911\nEpoch 4/24 - Validation loss: 1.1400, Accuracy: 0.5594\nEpoch 5/24 - Training loss: 1.0271, Accuracy: 0.6102\nEpoch 5/24 - Validation loss: 1.1413, Accuracy: 0.5762\nEpoch 6/24 - Training loss: 0.9770, Accuracy: 0.6307\nEpoch 6/24 - Validation loss: 1.1066, Accuracy: 0.5776\nEpoch 7/24 - Training loss: 0.9334, Accuracy: 0.6488\nEpoch 7/24 - Validation loss: 1.1030, Accuracy: 0.5886\nEpoch 8/24 - Training loss: 0.8760, Accuracy: 0.6690\nEpoch 8/24 - Validation loss: 1.1300, Accuracy: 0.5825\nEpoch 9/24 - Training loss: 0.8323, Accuracy: 0.6880\nEpoch 9/24 - Validation loss: 1.1303, Accuracy: 0.5955\nEpoch 10/24 - Training loss: 0.7823, Accuracy: 0.7111\nEpoch 10/24 - Validation loss: 1.1608, Accuracy: 0.5860\nEpoch 11/24 - Training loss: 0.7286, Accuracy: 0.7280\nEpoch 11/24 - Validation loss: 1.1692, Accuracy: 0.5893\nEpoch 12/24 - Training loss: 0.6867, Accuracy: 0.7464\nEpoch 12/24 - Validation loss: 1.2027, Accuracy: 0.6033\nEpoch 13/24 - Training loss: 0.6381, Accuracy: 0.7657\nEpoch 13/24 - Validation loss: 1.2484, Accuracy: 0.5964\nEpoch 14/24 - Training loss: 0.5852, Accuracy: 0.7874\nEpoch 14/24 - Validation loss: 1.2347, Accuracy: 0.5987\nEpoch 15/24 - Training loss: 0.5515, Accuracy: 0.8009\nEpoch 15/24 - Validation loss: 1.2868, Accuracy: 0.5922\nEpoch 16/24 - Training loss: 0.5200, Accuracy: 0.8118\nEpoch 16/24 - Validation loss: 1.3924, Accuracy: 0.5972\nEpoch 17/24 - Training loss: 0.4767, Accuracy: 0.8296\nEpoch 17/24 - Validation loss: 1.3579, Accuracy: 0.5895\nEpoch 18/24 - Training loss: 0.4527, Accuracy: 0.8340\nEpoch 18/24 - Validation loss: 1.4451, Accuracy: 0.5958\nEpoch 19/24 - Training loss: 0.4201, Accuracy: 0.8486\nEpoch 19/24 - Validation loss: 1.4213, Accuracy: 0.5960\nEpoch 20/24 - Training loss: 0.3948, Accuracy: 0.8570\nEpoch 20/24 - Validation loss: 1.4549, Accuracy: 0.5949\nEpoch 21/24 - Training loss: 0.3790, Accuracy: 0.8638\nEpoch 21/24 - Validation loss: 1.4817, Accuracy: 0.5969\nEpoch 22/24 - Training loss: 0.3584, Accuracy: 0.8709\nEpoch 22/24 - Validation loss: 1.5578, Accuracy: 0.5948\nEpoch 23/24 - Training loss: 0.3324, Accuracy: 0.8816\nEpoch 23/24 - Validation loss: 1.5515, Accuracy: 0.5987\nEpoch 24/24 - Training loss: 0.3184, Accuracy: 0.8894\nEpoch 24/24 - Validation loss: 1.6576, Accuracy: 0.6026\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\ntest_loss = 0.0\ntest_corrects = 0\n\n# You should define nb_test_samples before this block\n# It should be the total number of samples in the test set\nnb_test_samples = len(test_dataloader.dataset)\n\nwith torch.no_grad():\n    for inputs, labels in test_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item() * inputs.size(0)\n\n        _, preds = torch.max(outputs, 1)\n        test_corrects += torch.sum(preds == labels.data).item()\n\n# Calculate the average loss and accuracy\ntest_epoch_loss = test_loss / nb_test_samples\ntest_epoch_accuracy = test_corrects / nb_test_samples\ntest_accuracy_percentage = test_epoch_accuracy * 100\n\nprint(f'Test loss: {test_epoch_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy_percentage:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T03:09:47.187252Z","iopub.execute_input":"2024-04-08T03:09:47.187655Z","iopub.status.idle":"2024-04-08T03:10:07.690960Z","shell.execute_reply.started":"2024-04-08T03:09:47.187624Z","shell.execute_reply":"2024-04-08T03:10:07.689914Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Test loss: 1.5340\nTest Accuracy: 62.55%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}