{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8049663,"sourceType":"datasetVersion","datasetId":4746924}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\n!pip install torchsummary\nimport torch.nn as nn\nfrom torchvision import models\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T17:38:46.258951Z","iopub.execute_input":"2024-04-22T17:38:46.259848Z","iopub.status.idle":"2024-04-22T17:39:07.518316Z","shell.execute_reply.started":"2024-04-22T17:38:46.259818Z","shell.execute_reply":"2024-04-22T17:39:07.517225Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:39:25.709268Z","iopub.execute_input":"2024-04-22T17:39:25.710388Z","iopub.status.idle":"2024-04-22T17:39:25.763484Z","shell.execute_reply.started":"2024-04-22T17:39:25.710350Z","shell.execute_reply":"2024-04-22T17:39:25.762551Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"# minibatch size\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:39:27.979011Z","iopub.execute_input":"2024-04-22T17:39:27.979863Z","iopub.status.idle":"2024-04-22T17:39:27.983573Z","shell.execute_reply.started":"2024-04-22T17:39:27.979835Z","shell.execute_reply":"2024-04-22T17:39:27.982583Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\n\n# Define resize operation\nresize = transforms.Resize((98, 98))\n\n# Define transformations for both training and testing\ntransformations = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n    resize,\n    transforms.RandomHorizontalFlip(),  # Data augmentation\n    transforms.RandomRotation(10),  # Data augmentation\n    transforms.RandomResizedCrop((98, 98), scale=(0.8, 1.2), interpolation=Image.BILINEAR),  # Random crop\n    #transforms.RandomApply([transforms.RandomErasing()], p=0.5),  # Random erasing\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,)),  # Normalizing for grayscale image\n])\n\n# Use the same transformations for both training and testing datasets\ntrainTransforms = transformations\ntestTransforms = transformations\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:39:30.082247Z","iopub.execute_input":"2024-04-22T17:39:30.082940Z","iopub.status.idle":"2024-04-22T17:39:30.090585Z","shell.execute_reply.started":"2024-04-22T17:39:30.082911Z","shell.execute_reply":"2024-04-22T17:39:30.089392Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split\n\n\n# Load the dataset from the image folder\ndataset = datasets.ImageFolder(root='/kaggle/input/facial-emotion-detection/Facial emotion/train', transform=trainTransforms)\n\n# Calculate the sizes for train and validation sets\ntrain_size = int(0.7 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Split the dataset\ntrain_data, validation_data = random_split(dataset, [train_size, val_size])\n# Setup the batch size hyperparameter\nBATCH_SIZE = batch_size\ntest_data = ImageFolder('//kaggle/input/facial-emotion-detection/Facial emotion/test', transform=testTransforms)\n\n# Turn datasets into iterables (batches)\ntrain_dataloader = DataLoader(train_data,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\nvalidation_dataloader = DataLoader(validation_data,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\ntest_dataloader = DataLoader(test_data,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False)\n\n\n# Let's check out what we've created\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of Validation dataloader: {len(validation_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:39:36.401457Z","iopub.execute_input":"2024-04-22T17:39:36.402189Z","iopub.status.idle":"2024-04-22T17:40:09.860355Z","shell.execute_reply.started":"2024-04-22T17:39:36.402156Z","shell.execute_reply":"2024-04-22T17:40:09.859489Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f834a1ca020>, <torch.utils.data.dataloader.DataLoader object at 0x7f834a0bd390>)\nLength of train dataloader: 1256 batches of 16\nLength of Validation dataloader: 539 batches of 16\nLength of test dataloader: 449 batches of 16\n","output_type":"stream"}]},{"cell_type":"code","source":"nb_train_samples = 1256 * 16\nnb_validation_samples = 539 * 16\nnb_test_samples = 449 * 16","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:40:13.257549Z","iopub.execute_input":"2024-04-22T17:40:13.258213Z","iopub.status.idle":"2024-04-22T17:40:13.262679Z","shell.execute_reply.started":"2024-04-22T17:40:13.258181Z","shell.execute_reply":"2024-04-22T17:40:13.261662Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Defining the neural network\nclass FIVE_CNN(nn.Module):\n    def __init__(self):\n        super(FIVE_CNN, self).__init__()\n        \n        # Convolutional blocks: Conv layer => BatchNorm => ReLU\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        \n        # Adaptive average pooling\n        self.adaptive_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Fully connected layers\n        self.fc_layers = nn.Sequential(\n            nn.Linear(1024, 4096),  # Adjust the linear layer size based on your conv output\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 7),\n        ) \n        \n  \n\n    def forward(self, x):\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        x = self.conv_block4(x)\n        x = self.conv_block5(x)\n        x = self.adaptive_avg_pool(x)\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n        x = self.fc_layers(x)\n        return x\n\n# Instantiating the model\nmodel = FIVE_CNN()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:40:15.819654Z","iopub.execute_input":"2024-04-22T17:40:15.820010Z","iopub.status.idle":"2024-04-22T17:40:16.142922Z","shell.execute_reply.started":"2024-04-22T17:40:15.819981Z","shell.execute_reply":"2024-04-22T17:40:16.142074Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Define Kullback-Leibler Divergence (KLD) Loss Function\nimport torch.nn.functional as F\n\ndef kld_loss(outputs, labels):\n    log_probs = F.log_softmax(outputs, dim=1)\n    target_probs = F.one_hot(labels, num_classes=outputs.size(1))  # Convert labels to one-hot vectors\n    target_probs = target_probs.float()\n    return F.kl_div(log_probs, target_probs, reduction='batchmean')\n \n\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\nmodel=model.to(device)\n# Scheduler\nscheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.75, patience=5, verbose=True)\n\n\n# Number of epochs\nnum_epochs = 50\n\n\n\n# Move model to GPU if available\nmodel = model.to(device)\n\n# Training Loop\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n\n    for inputs, labels in train_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = kld_loss(outputs, labels)  # Use KLD loss here\n        _, preds = torch.max(outputs, 1)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / len(train_dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Training loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n\n    # Validation phase\n    model.eval()\n    val_running_loss = 0.0\n    val_running_corrects = 0\n    \n    with torch.no_grad():\n        for inputs, labels in validation_dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = kld_loss(outputs, labels)  # Use KLD loss here\n            _, preds = torch.max(outputs, 1)\n            val_running_loss += loss.item() * inputs.size(0)\n            val_running_corrects += torch.sum(preds == labels.data)\n\n    val_epoch_loss = val_running_loss / len(validation_dataloader.dataset)\n    val_epoch_acc = val_running_corrects.double() / len(validation_dataloader.dataset)\n    print(f'Epoch {epoch}/{num_epochs - 1} - Validation loss: {val_epoch_loss:.4f}, Accuracy: {val_epoch_acc:.4f}')\n\n    \n\n# Save the model after training\n#torch.save(model.state_dict(), 'vggnet_kld_adam.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:40:42.259472Z","iopub.execute_input":"2024-04-22T17:40:42.259840Z","iopub.status.idle":"2024-04-22T18:56:09.613952Z","shell.execute_reply.started":"2024-04-22T17:40:42.259809Z","shell.execute_reply":"2024-04-22T18:56:09.612955Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 0/49 - Training loss: 1.7699, Accuracy: 0.2675\nEpoch 0/49 - Validation loss: 1.6730, Accuracy: 0.3206\nEpoch 1/49 - Training loss: 1.6013, Accuracy: 0.3640\nEpoch 1/49 - Validation loss: 1.5978, Accuracy: 0.3798\nEpoch 2/49 - Training loss: 1.4861, Accuracy: 0.4189\nEpoch 2/49 - Validation loss: 1.4486, Accuracy: 0.4427\nEpoch 3/49 - Training loss: 1.4144, Accuracy: 0.4512\nEpoch 3/49 - Validation loss: 1.3666, Accuracy: 0.4747\nEpoch 4/49 - Training loss: 1.3586, Accuracy: 0.4752\nEpoch 4/49 - Validation loss: 1.2975, Accuracy: 0.5017\nEpoch 5/49 - Training loss: 1.3081, Accuracy: 0.4986\nEpoch 5/49 - Validation loss: 1.2593, Accuracy: 0.5200\nEpoch 6/49 - Training loss: 1.2717, Accuracy: 0.5113\nEpoch 6/49 - Validation loss: 1.2887, Accuracy: 0.4988\nEpoch 7/49 - Training loss: 1.2463, Accuracy: 0.5243\nEpoch 7/49 - Validation loss: 1.1950, Accuracy: 0.5478\nEpoch 8/49 - Training loss: 1.2087, Accuracy: 0.5402\nEpoch 8/49 - Validation loss: 1.1682, Accuracy: 0.5573\nEpoch 9/49 - Training loss: 1.1961, Accuracy: 0.5412\nEpoch 9/49 - Validation loss: 1.1863, Accuracy: 0.5501\nEpoch 10/49 - Training loss: 1.1725, Accuracy: 0.5515\nEpoch 10/49 - Validation loss: 1.1955, Accuracy: 0.5479\nEpoch 11/49 - Training loss: 1.1547, Accuracy: 0.5582\nEpoch 11/49 - Validation loss: 1.1472, Accuracy: 0.5689\nEpoch 12/49 - Training loss: 1.1421, Accuracy: 0.5586\nEpoch 12/49 - Validation loss: 1.2133, Accuracy: 0.5453\nEpoch 13/49 - Training loss: 1.1235, Accuracy: 0.5724\nEpoch 13/49 - Validation loss: 1.1438, Accuracy: 0.5645\nEpoch 14/49 - Training loss: 1.1092, Accuracy: 0.5780\nEpoch 14/49 - Validation loss: 1.1265, Accuracy: 0.5811\nEpoch 15/49 - Training loss: 1.0974, Accuracy: 0.5830\nEpoch 15/49 - Validation loss: 1.1133, Accuracy: 0.5761\nEpoch 16/49 - Training loss: 1.0811, Accuracy: 0.5918\nEpoch 16/49 - Validation loss: 1.0894, Accuracy: 0.5881\nEpoch 17/49 - Training loss: 1.0683, Accuracy: 0.5969\nEpoch 17/49 - Validation loss: 1.1398, Accuracy: 0.5823\nEpoch 18/49 - Training loss: 1.0536, Accuracy: 0.6002\nEpoch 18/49 - Validation loss: 1.0772, Accuracy: 0.5912\nEpoch 19/49 - Training loss: 1.0438, Accuracy: 0.6053\nEpoch 19/49 - Validation loss: 1.0908, Accuracy: 0.5879\nEpoch 20/49 - Training loss: 1.0318, Accuracy: 0.6058\nEpoch 20/49 - Validation loss: 1.1037, Accuracy: 0.5848\nEpoch 21/49 - Training loss: 1.0231, Accuracy: 0.6092\nEpoch 21/49 - Validation loss: 1.0542, Accuracy: 0.5994\nEpoch 22/49 - Training loss: 1.0148, Accuracy: 0.6181\nEpoch 22/49 - Validation loss: 1.0458, Accuracy: 0.6021\nEpoch 23/49 - Training loss: 1.0023, Accuracy: 0.6233\nEpoch 23/49 - Validation loss: 1.0619, Accuracy: 0.5936\nEpoch 24/49 - Training loss: 0.9904, Accuracy: 0.6261\nEpoch 24/49 - Validation loss: 1.0597, Accuracy: 0.6022\nEpoch 25/49 - Training loss: 0.9816, Accuracy: 0.6278\nEpoch 25/49 - Validation loss: 1.0651, Accuracy: 0.5982\nEpoch 26/49 - Training loss: 0.9746, Accuracy: 0.6303\nEpoch 26/49 - Validation loss: 1.0625, Accuracy: 0.6066\nEpoch 27/49 - Training loss: 0.9615, Accuracy: 0.6348\nEpoch 27/49 - Validation loss: 1.1297, Accuracy: 0.5884\nEpoch 28/49 - Training loss: 0.9528, Accuracy: 0.6411\nEpoch 28/49 - Validation loss: 1.0309, Accuracy: 0.6111\nEpoch 29/49 - Training loss: 0.9338, Accuracy: 0.6483\nEpoch 29/49 - Validation loss: 1.0822, Accuracy: 0.5941\nEpoch 30/49 - Training loss: 0.9381, Accuracy: 0.6450\nEpoch 30/49 - Validation loss: 1.1424, Accuracy: 0.5769\nEpoch 31/49 - Training loss: 0.9210, Accuracy: 0.6519\nEpoch 31/49 - Validation loss: 1.0509, Accuracy: 0.6102\nEpoch 32/49 - Training loss: 0.9132, Accuracy: 0.6532\nEpoch 32/49 - Validation loss: 1.0525, Accuracy: 0.6025\nEpoch 33/49 - Training loss: 0.9033, Accuracy: 0.6611\nEpoch 33/49 - Validation loss: 1.1055, Accuracy: 0.5899\nEpoch 34/49 - Training loss: 0.8954, Accuracy: 0.6636\nEpoch 34/49 - Validation loss: 1.0404, Accuracy: 0.6106\nEpoch 35/49 - Training loss: 0.8759, Accuracy: 0.6689\nEpoch 35/49 - Validation loss: 1.1310, Accuracy: 0.5833\nEpoch 36/49 - Training loss: 0.8734, Accuracy: 0.6706\nEpoch 36/49 - Validation loss: 1.1240, Accuracy: 0.5990\nEpoch 37/49 - Training loss: 0.8670, Accuracy: 0.6754\nEpoch 37/49 - Validation loss: 1.0999, Accuracy: 0.5936\nEpoch 38/49 - Training loss: 0.8553, Accuracy: 0.6792\nEpoch 38/49 - Validation loss: 1.0292, Accuracy: 0.6239\nEpoch 39/49 - Training loss: 0.8479, Accuracy: 0.6788\nEpoch 39/49 - Validation loss: 1.0694, Accuracy: 0.6133\nEpoch 40/49 - Training loss: 0.8423, Accuracy: 0.6821\nEpoch 40/49 - Validation loss: 1.0994, Accuracy: 0.6021\nEpoch 41/49 - Training loss: 0.8376, Accuracy: 0.6850\nEpoch 41/49 - Validation loss: 1.0846, Accuracy: 0.6105\nEpoch 42/49 - Training loss: 0.8249, Accuracy: 0.6871\nEpoch 42/49 - Validation loss: 1.0422, Accuracy: 0.6225\nEpoch 43/49 - Training loss: 0.8172, Accuracy: 0.6926\nEpoch 43/49 - Validation loss: 1.1965, Accuracy: 0.5763\nEpoch 44/49 - Training loss: 0.8060, Accuracy: 0.6994\nEpoch 44/49 - Validation loss: 1.0700, Accuracy: 0.6236\nEpoch 45/49 - Training loss: 0.7951, Accuracy: 0.7052\nEpoch 45/49 - Validation loss: 1.0940, Accuracy: 0.6056\nEpoch 46/49 - Training loss: 0.7844, Accuracy: 0.7058\nEpoch 46/49 - Validation loss: 1.0875, Accuracy: 0.6137\nEpoch 47/49 - Training loss: 0.7773, Accuracy: 0.7098\nEpoch 47/49 - Validation loss: 1.1524, Accuracy: 0.5899\nEpoch 48/49 - Training loss: 0.7769, Accuracy: 0.7066\nEpoch 48/49 - Validation loss: 1.1086, Accuracy: 0.5940\nEpoch 49/49 - Training loss: 0.7663, Accuracy: 0.7126\nEpoch 49/49 - Validation loss: 1.0629, Accuracy: 0.6119\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\ntest_loss = 0.0\ntest_corrects = 0\n\n# You should define nb_test_samples before this block\n# It should be the total number of samples in the test set\nnb_test_samples = len(test_dataloader.dataset)\n\nwith torch.no_grad():\n    for inputs, labels in test_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = kld_loss(outputs, labels)\n        test_loss += loss.item() * inputs.size(0)\n\n        _, preds = torch.max(outputs, 1)\n        test_corrects += torch.sum(preds == labels.data).item()\n\n# Calculate the average loss and accuracy\ntest_epoch_loss = test_loss / nb_test_samples\ntest_epoch_accuracy = test_corrects / nb_test_samples\ntest_accuracy_percentage = test_epoch_accuracy * 100\n\nprint(f'Test loss: {test_epoch_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy_percentage:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:10:58.288653Z","iopub.execute_input":"2024-04-22T19:10:58.289103Z","iopub.status.idle":"2024-04-22T19:12:01.390259Z","shell.execute_reply.started":"2024-04-22T19:10:58.289070Z","shell.execute_reply":"2024-04-22T19:12:01.389193Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Test loss: 1.0782\nTest Accuracy: 60.53%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}